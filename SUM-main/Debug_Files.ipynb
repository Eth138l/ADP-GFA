{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bc19c49a-f410-4adb-9bfc-62e01d17c40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: datasets1/AI4VA/val/val_fixation/Vaillant_0471_1954_05_23-14.png\n",
      "Processed and saved: datasets1/AI4VA/val/val_fixation/Vaillant_0479_1954_07_18-01.png\n",
      "Processed and saved: datasets1/AI4VA/val/val_fixation/Vaillant_0480_1954_07_25-01.png\n",
      "Processed and saved: datasets1/AI4VA/val/val_fixation/Vaillant_0485_1954_08_29-01.png\n",
      "Processed and saved: datasets1/AI4VA/val/val_fixation/Vaillant_0525_1955_06_05-16.png\n",
      "Processed and saved: datasets1/AI4VA/val/val_fixation/Vaillant_0553_1955_12_18-06.png\n",
      "Processed and saved: datasets1/AI4VA/val/val_fixation/Vaillant_0608_1957_01_06-06.png\n"
     ]
    }
   ],
   "source": [
    "### 输出显著性块\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def generate_fixation_map(saliency_map, threshold=0.85, num_fixations=100, point_size=3):\n",
    "    \"\"\"\n",
    "    从显著性图生成注视点图，使用较大的点来表示注视点，确保覆盖显著区域。\n",
    "\n",
    "    参数:\n",
    "    - saliency_map: 输入的显著性图，值在 0-255 之间的灰度图。\n",
    "    - threshold: 阈值，用于限制注视点生成区域，值应在 0-1 之间。\n",
    "    - num_fixations: 生成的注视点数量。\n",
    "    - point_size: 注视点的大小，用于可视化。\n",
    "\n",
    "    返回:\n",
    "    - fixation_map: 注视点图，注视点为1，背景为0。\n",
    "    \"\"\"\n",
    "    # 归一化显著性图到 [0, 1]\n",
    "    saliency_map = saliency_map.astype(np.float32) / 255.0\n",
    "\n",
    "    # 阈值处理，选择显著性高于阈值的区域\n",
    "    high_saliency_indices = np.where(saliency_map >= threshold)\n",
    "\n",
    "    # 如果没有满足阈值的区域，直接返回空白注视点图\n",
    "    if len(high_saliency_indices[0]) == 0:\n",
    "        return np.zeros_like(saliency_map)\n",
    "\n",
    "    # 创建空白的注视点图\n",
    "    fixation_map = np.zeros_like(saliency_map)\n",
    "\n",
    "    # 确保显著区域都覆盖：在显著性较高的区域生成点\n",
    "    for i in range(len(high_saliency_indices[0])):\n",
    "        y, x = high_saliency_indices[0][i], high_saliency_indices[1][i]\n",
    "        # 将选中的点扩展为一个小区域，例如 3x3 或 5x5\n",
    "        fixation_map[max(0, y-point_size//2):min(fixation_map.shape[0], y+point_size//2+1),\n",
    "                     max(0, x-point_size//2):min(fixation_map.shape[1], x+point_size//2+1)] = 1\n",
    "\n",
    "    # 随机从高显著性区域中选择部分点作为主要注视点（可选）\n",
    "    if len(high_saliency_indices[0]) > num_fixations:\n",
    "        selected_indices = np.random.choice(len(high_saliency_indices[0]), num_fixations, replace=False)\n",
    "        for idx in selected_indices:\n",
    "            y, x = high_saliency_indices[0][idx], high_saliency_indices[1][idx]\n",
    "            # 增大主要注视点的大小以更好地表示\n",
    "            fixation_map[max(0, y-point_size//2):min(fixation_map.shape[0], y+point_size//2+1),\n",
    "                         max(0, x-point_size//2):min(fixation_map.shape[1], x+point_size//2+1)] = 1\n",
    "\n",
    "    return fixation_map\n",
    "\n",
    "def process_images(input_folder, output_folder, threshold=0.15, num_fixations=100, point_size=1):\n",
    "    \"\"\"\n",
    "    从输入文件夹读取所有图像文件，生成注视点图并保存到输出文件夹。\n",
    "\n",
    "    参数:\n",
    "    - input_folder: 输入图像文件夹路径。\n",
    "    - output_folder: 输出图像文件夹路径。\n",
    "    - threshold: 生成注视点图的显著性阈值。\n",
    "    - num_fixations: 每张图生成的注视点数量。\n",
    "    - point_size: 注视点的大小。\n",
    "    \"\"\"\n",
    "    # 创建输出文件夹（如果不存在）\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 遍历输入文件夹中的所有文件\n",
    "    for filename in os.listdir(input_folder):\n",
    "        # 构建完整的文件路径\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        \n",
    "        # 确保只处理图像文件\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "        \n",
    "        # 读取显著性图（灰度图）\n",
    "        saliency_map = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # 生成注视点图\n",
    "        fixation_map = generate_fixation_map(saliency_map, threshold=threshold, num_fixations=num_fixations, point_size=point_size)\n",
    "\n",
    "        # 构建输出文件路径\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "\n",
    "        # 保存注视点图\n",
    "        cv2.imwrite(output_path, fixation_map * 255)  # 乘以255以保存为8位图像\n",
    "\n",
    "        # 可选：显示处理进度\n",
    "        print(f'Processed and saved: {output_path}')\n",
    "\n",
    "# 定义文件夹路径\n",
    "#input_folder = 'datasets/AI4VA/train/train_saliency'\n",
    "#output_folder = 'datasets/AI4VA/train/train_fixation'\n",
    "\n",
    "#input_folder = 'datasets/AI4VA/val/val_saliency'\n",
    "#output_folder = 'datasets/AI4VA/val/val_fixation'\n",
    "\n",
    "# 定义文件夹2路径(双线程)\n",
    "#input_folder = 'datasets1/AI4VA/train/train_saliency'\n",
    "#output_folder = 'datasets1/AI4VA/train/train_fixation'\n",
    "\n",
    "input_folder = 'datasets1/AI4VA/val/val_saliency'\n",
    "output_folder = 'datasets1/AI4VA/val/val_fixation'\n",
    "\n",
    "# 处理所有图像\n",
    "process_images(input_folder, output_folder, threshold=0.3, num_fixations=100, point_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b9eba16-509a-423b-9726-afe61bc8c430",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0460_1954_03_07-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0466_1954_04_18-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0470_1954_05_16-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0470_1954_05_16-14.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0473_1954_06_06-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0476_1954_06_27-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0477_1954_07_04-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0479_1954_07_18-14.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0484_1954_08_22-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0489_1954_09_26-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0499_1954_12_05-01.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0538_1955_09_04-16.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0617_1957_03_10-06.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0618_1957_03_17-06.png\n",
      "Fixations image saved to datasets/AI4VA/train/train_fixation/Vaillant_0622_1957_04_14-32.png\n"
     ]
    }
   ],
   "source": [
    "# step1 根据预测图生成注视点\n",
    "import cv2\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# 读取显著性预测图\n",
    "def load_saliency_map(file_path):\n",
    "    return cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 应用阈值化处理\n",
    "def apply_threshold(saliency_map):\n",
    "    _, binary_map = cv2.threshold(saliency_map, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary_map\n",
    "\n",
    "# 在显著性高的地方生成更多注视点\n",
    "def generate_dense_fixations(saliency_map, num_points=1500):\n",
    "    height, width = saliency_map.shape\n",
    "    fixations = []\n",
    "    \n",
    "    # 将显著性图像的值归一化，作为概率分布\n",
    "    normalized_map = saliency_map.astype(float) / 255.0\n",
    "    ############################################################\n",
    "    # 确保归一化后的值在 [0, 1] 之间\n",
    "    normalized_map = np.clip(normalized_map, 0, 1)\n",
    "    \n",
    "    # 防止概率分布和为0\n",
    "    if normalized_map.sum() == 0:\n",
    "        raise ValueError(\"Normalized saliency map has no valid values. Sum of values is zero.\")\n",
    "    ############################################################\n",
    "    normalized_map /= normalized_map.sum()  # 确保概率总和为1\n",
    "\n",
    "    # 将显著性图像展平为一维数组，方便使用np.random.choice生成注视点\n",
    "    flat_map = normalized_map.flatten()\n",
    "    \n",
    "    # 生成(num_points)个注视点，根据显著性图中的像素值作为概率\n",
    "    indices = np.random.choice(height * width, num_points, p=flat_map)\n",
    "\n",
    "    # 将一维索引转换为二维的(x, y)坐标\n",
    "    for idx in indices:\n",
    "        x = idx % width\n",
    "        y = idx // width\n",
    "        fixations.append((x, y))\n",
    "    \n",
    "    return fixations\n",
    "\n",
    "# 计算每个注视点的持续时间\n",
    "def calculate_fixation_times(saliency_map, fixations):\n",
    "    fixation_times = [saliency_map[y, x] / 255.0 for x, y in fixations]\n",
    "    return fixation_times\n",
    "\n",
    "# 保存注视点及其时间到CSV文件\n",
    "def save_fixations_to_csv(file_path, fixations, fixation_times):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['x', 'y', 'duration']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        \n",
    "        writer.writeheader()\n",
    "        for (x, y), duration in zip(fixations, fixation_times):\n",
    "            writer.writerow({'x': x, 'y': y, 'duration': duration})\n",
    "\n",
    "# 绘制注视点并保存为新图像\n",
    "def draw_fixations(fixations, output_image_path, image_size):\n",
    "    # 创建一个黑色背景的新图像\n",
    "    image_with_fixations = np.zeros((image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "    \n",
    "    # 绘制注视点（小的白色圆点）\n",
    "    for (x, y) in fixations:\n",
    "        cv2.circle(image_with_fixations, (x, y), 2, (255, 255, 255), -1)  # 白色圆点，半径为2\n",
    "    \n",
    "    # 保存图像\n",
    "    cv2.imwrite(output_image_path, image_with_fixations)\n",
    "\n",
    "# 处理单个文件的函数\n",
    "def process_image(saliency_map_path, output_image_folder, output_csv_folder, num_fixations=500):\n",
    "    # 获取图像的文件名（不带扩展名）\n",
    "    base_name = os.path.splitext(os.path.basename(saliency_map_path))[0]\n",
    "    \n",
    "    # 生成输出文件路径\n",
    "    fixation_output_csv_path = os.path.join(output_csv_folder, f'{base_name}_fixations.csv')\n",
    "    fixation_output_image_path = os.path.join(output_image_folder, f'{base_name}.png')\n",
    "    \n",
    "    # 读取显著性预测图\n",
    "    saliency_map = load_saliency_map(saliency_map_path)\n",
    "    \n",
    "    # 应用阈值化处理\n",
    "    saliency_map = apply_threshold(saliency_map)\n",
    "    \n",
    "    # 生成密集的注视点，在显著性高的区域生成更多注视点\n",
    "    fixations = generate_dense_fixations(saliency_map, num_points=num_fixations)\n",
    "    \n",
    "    # 计算每个注视点的持续时间\n",
    "    fixation_times = calculate_fixation_times(saliency_map, fixations)\n",
    "    \n",
    "    # 保存注视点及其时间到CSV文件\n",
    "    save_fixations_to_csv(fixation_output_csv_path, fixations, fixation_times)\n",
    "    \n",
    "    # 绘制注视点并保存为新图像\n",
    "    image_size = saliency_map.shape\n",
    "    draw_fixations(fixations, fixation_output_image_path, image_size)\n",
    "    \n",
    "    # print(f'Fixations saved to {fixation_output_csv_path}')\n",
    "    print(f'Fixations image saved to {fixation_output_image_path}')\n",
    "\n",
    "# 主函数，批处理文件夹中的所有图像\n",
    "def main():\n",
    "    input_folder = 'datasets/AI4VA/train/train_saliency'\n",
    "    # input_folder = 'datasets/AI4VA/val/val_saliency'\n",
    "    # 输出文件夹路径\n",
    "    output_image_folder = 'datasets/AI4VA/train/train_fixation'\n",
    "    # output_image_folder = 'datasets/AI4VA/val/val_fixation'\n",
    "    \n",
    "    output_csv_folder = 'output_csv_val'\n",
    "    \n",
    "    # 确保输出文件夹存在\n",
    "    os.makedirs(output_image_folder, exist_ok=True)\n",
    "    os.makedirs(output_csv_folder, exist_ok=True)\n",
    "    \n",
    "    # 批处理输入文件夹中的所有图像文件\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):  # 可根据需要添加更多扩展名\n",
    "            saliency_map_path = os.path.join(input_folder, filename)\n",
    "            process_image(saliency_map_path, output_image_folder, output_csv_folder)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "84dd80b9-75e9-499e-bbd3-497f5012cbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted SUM_newK8/Vaillant_0471_1954_05_23-14.png to black and white and saved as SUM_newK8/SUM_newK8_heibai/Vaillant_0471_1954_05_23-14.png\n",
      "Converted SUM_newK8/Vaillant_0479_1954_07_18-01.png to black and white and saved as SUM_newK8/SUM_newK8_heibai/Vaillant_0479_1954_07_18-01.png\n",
      "Converted SUM_newK8/Vaillant_0480_1954_07_25-01.png to black and white and saved as SUM_newK8/SUM_newK8_heibai/Vaillant_0480_1954_07_25-01.png\n",
      "Converted SUM_newK8/Vaillant_0485_1954_08_29-01.png to black and white and saved as SUM_newK8/SUM_newK8_heibai/Vaillant_0485_1954_08_29-01.png\n",
      "Converted SUM_newK8/Vaillant_0525_1955_06_05-16.png to black and white and saved as SUM_newK8/SUM_newK8_heibai/Vaillant_0525_1955_06_05-16.png\n",
      "Converted SUM_newK8/Vaillant_0553_1955_12_18-06.png to black and white and saved as SUM_newK8/SUM_newK8_heibai/Vaillant_0553_1955_12_18-06.png\n",
      "Converted SUM_newK8/Vaillant_0608_1957_01_06-06.png to black and white and saved as SUM_newK8/SUM_newK8_heibai/Vaillant_0608_1957_01_06-06.png\n"
     ]
    }
   ],
   "source": [
    "# 将热力图变为黑白色图像\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def convert_heatmap_to_bw(heatmap_path, output_path):\n",
    "    # 读取热力图像\n",
    "    heatmap = cv2.imread(heatmap_path)\n",
    "\n",
    "    # 检查图像是否成功加载\n",
    "    if heatmap is None:\n",
    "        print(f\"Failed to load image {heatmap_path}\")\n",
    "        return\n",
    "\n",
    "    # 转换为灰度图像\n",
    "    gray_heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 归一化到 [0, 255]，并转换为无符号 8 位整数\n",
    "    normalized_gray = cv2.normalize(gray_heatmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # 保存黑白显著性图像\n",
    "    cv2.imwrite(output_path, normalized_gray)\n",
    "\n",
    "    print(f\"Converted {heatmap_path} to black and white and saved as {output_path}\")\n",
    "\n",
    "# 示例使用\n",
    "input_folder = \"SUM_newK8\"  # 热力图文件夹\n",
    "output_folder = \"SUM_newK8/SUM_newK8_heibai\"  # 输出文件夹\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 处理文件夹中的所有图像\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):  # 根据图像格式修改\n",
    "        heatmap_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder,filename)\n",
    "        convert_heatmap_to_bw(heatmap_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a721e872-bc88-4d70-8175-199b944acd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，模糊后的图像已保存到输出文件夹。\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# 输入与输出文件夹路径\n",
    "input_folder = 'SUM_newK8/SUM_newK8_heibai/'  # 替换为你的输入文件夹路径\n",
    "output_folder = 'SUM_newK8/SUM_newK8_gaosi23/'  # 替换为你的输出文件夹路径\n",
    "\n",
    "# 检查输出文件夹是否存在，不存在则创建\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# 设置高斯模糊的核大小 (kernel size)，值越大模糊越明显，必须是奇数\n",
    "kernel_size = (23, 23)\n",
    "\n",
    "# 遍历输入文件夹中的所有图片\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\") or filename.endswith(\".bmp\"):  # 仅处理指定格式的图片\n",
    "        img_path = os.path.join(input_folder, filename)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # 以灰度模式读取图片\n",
    "\n",
    "        # 对图像进行高斯模糊处理\n",
    "        blurred_img = cv2.GaussianBlur(img, kernel_size, 0)\n",
    "\n",
    "        # 保存处理后的图像到输出文件夹\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, blurred_img)\n",
    "\n",
    "print(\"处理完成，模糊后的图像已保存到输出文件夹。\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e281d969-58ec-42e6-972f-eafeb82d6cca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved to val_id.csv\n"
     ]
    }
   ],
   "source": [
    "#根据文件制作csv文件\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def generate_train_ids_csv(input_folder, output_csv_path):\n",
    "    # 打开CSV文件进行写入\n",
    "    with open(output_csv_path, mode='w', newline='') as csv_file:\n",
    "        fieldnames = ['image', 'map', 'fixation']\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "        \n",
    "        # 写入表头\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # 遍历文件夹中的所有图片\n",
    "        for filename in os.listdir(input_folder):\n",
    "            if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "                # 假设原始图像名是 filename，显著性图和注视点文件都以相同的基础名命名，只是后缀不同\n",
    "                base_name = os.path.splitext(filename)[0]\n",
    "                \n",
    "                # 构建每列的文件名\n",
    "                image_name = filename  # 原始图像名\n",
    "                map_name = f\"{base_name}.png\" \n",
    "                fixation_name = f\"{base_name}.png\"  # 假设fixation文件名后缀为_fixations.png\n",
    "                \n",
    "                # 写入CSV文件\n",
    "                writer.writerow({'image': image_name, 'map': map_name, 'fixation': fixation_name})\n",
    "\n",
    "    print(f\"CSV file saved to {output_csv_path}\")\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    # 输入图像文件夹\n",
    "    input_folder = 'img_val'  # 替换为你的文件夹路径\n",
    "    # 输出CSV文件路径\n",
    "    output_csv_path = 'val_id.csv'\n",
    "    \n",
    "    # 生成CSV文件\n",
    "    generate_train_ids_csv(input_folder, output_csv_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "939b47c6-297f-428f-840e-a4e71ec08f7f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Vaillant_0471_1954_05_23-14.png\n",
      "Processed Vaillant_0479_1954_07_18-01.png\n",
      "Processed Vaillant_0480_1954_07_25-01.png\n",
      "Processed Vaillant_0485_1954_08_29-01.png\n",
      "Processed Vaillant_0525_1955_06_05-16.png\n",
      "Processed Vaillant_0553_1955_12_18-06.png\n",
      "Processed Vaillant_0608_1957_01_06-06.png\n",
      "All images have been resized.\n"
     ]
    }
   ],
   "source": [
    "#修改图片大小为512\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# 图像文件夹路径\n",
    "input_folder = 'data'\n",
    "output_folder = 'data/resize'\n",
    "\n",
    "# 创建输出文件夹（如果不存在的话）\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 目标图像大小\n",
    "target_size = (512, 512)\n",
    "\n",
    "# 遍历输入文件夹中的所有图片并调整大小\n",
    "def resize_images(input_folder, output_folder, target_size):\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.png') or filename.endswith('.jpg') or filename.endswith('.jpeg'):\n",
    "            # 构建完整的输入图像路径\n",
    "            img_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            # 打开图像并调整大小\n",
    "            img = Image.open(img_path)\n",
    "            img_resized = img.resize(target_size, Image.Resampling.LANCZOS)  # 使用LANCZOS替代ANTIALIAS\n",
    "            \n",
    "            # 构建输出图像路径\n",
    "            output_img_path = os.path.join(output_folder, filename)\n",
    "            \n",
    "            # 保存调整后的图像\n",
    "            img_resized.save(output_img_path)\n",
    "            \n",
    "            print(f\"Processed {filename}\")\n",
    "\n",
    "# 批处理所有图像\n",
    "resize_images(input_folder, output_folder, target_size)\n",
    "\n",
    "print(\"All images have been resized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b092301d-b479-49aa-981d-310112330de2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# 讲指定文件夹中的文件从256*256变为512*512\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def resize_images_in_folder(folder_path, new_size=(512, 512)):\n",
    "    # 遍历文件夹中的所有文件\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # 构建完整文件路径\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # 检查文件是否为图片\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            try:\n",
    "                # 打开图片\n",
    "                with Image.open(img_path) as img:\n",
    "                    # 检查图片大小是否是256x256\n",
    "                    if img.size == (256, 256):\n",
    "                        # 将图片大小调整为512x512\n",
    "                        resized_img = img.resize(new_size)\n",
    "                        # 保存图片，覆盖原图\n",
    "                        resized_img.save(img_path)\n",
    "                        # print(f\"Resized {filename} to {new_size}\")\n",
    "                    else:\n",
    "                        print(f\"Skipping {filename}: Image size is {img.size}, not 256x256\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {filename}: {e}\")\n",
    "\n",
    "folder_path = 'datasets/datasets_UI_256/val/val_fixation'\n",
    "resize_images_in_folder(folder_path)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33670e62-e3de-426c-9e1e-7dfba850577d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
